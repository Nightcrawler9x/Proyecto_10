{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE8lpwSIn_Lp",
        "outputId": "65ffba30-9a81-47d2-db9f-cfee082c9098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Proyecto_10' already exists and is not an empty directory.\n",
            "/content/Proyecto_10\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nightcrawler9x/Proyecto_10.git\n",
        "%cd Proyecto_10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import Uformer\n",
        "from losses import CharbonnierLoss"
      ],
      "metadata": {
        "id": "nsBdJBi0oyHX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from matplotlib.animation import FuncAnimation, PillowWriter\n",
        "!pip install opencv-python\n",
        "!pip install torchsummary\n",
        "import cv2\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr_loss, structural_similarity as ssim_loss"
      ],
      "metadata": {
        "id": "kybQtMumpOSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "import random\n",
        "\n",
        "class NYUDatasetNoDepth(Dataset):\n",
        "    def __init__(self,\n",
        "                 rgb_dir,\n",
        "                 input_size=256,\n",
        "                 dof_levels=5):\n",
        "        self.rgb_dir    = rgb_dir\n",
        "        self.input_size = input_size\n",
        "        self.dof_levels = dof_levels\n",
        "\n",
        "        # Solo archivos válidos\n",
        "        self.base_files = sorted([\n",
        "            f for f in os.listdir(rgb_dir)\n",
        "            if os.path.isfile(os.path.join(rgb_dir, f)) and f.endswith('.png')\n",
        "        ])\n",
        "\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize((self.input_size, self.input_size)),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.base_files[idx]\n",
        "        dof = random.randint(0, self.dof_levels - 1)  # dof aleatorio para cada imagen\n",
        "\n",
        "        # Cargar imagen con desenfoque\n",
        "        dof_path = os.path.join(self.rgb_dir, f'dof{dof}', name)\n",
        "        if not os.path.isfile(dof_path):\n",
        "            raise FileNotFoundError(f\"No se encontró la imagen desenfocada: {dof_path}\")\n",
        "\n",
        "        # Cargar ground truth (imagen nítida)\n",
        "        gt_path = os.path.join(self.rgb_dir, name)\n",
        "\n",
        "        dof_img = Image.open(dof_path).convert('RGB')\n",
        "        gt_img  = Image.open(gt_path).convert('RGB')\n",
        "\n",
        "        # Transformar (redimensionar y a tensor)\n",
        "        dof_img = self.transform(dof_img)\n",
        "        gt_img  = self.transform(gt_img)\n",
        "\n",
        "        return {\n",
        "            'image': dof_img,\n",
        "            'gt': gt_img,\n",
        "            'dof': dof,\n",
        "            'name': name\n",
        "        }"
      ],
      "metadata": {
        "id": "qQ0oBtcYpWie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_dir = '/content/drive/MyDrive/UIS/Handson/nyu_rgb' #copie la carpeta nyu_rgb del drive de samuel, y pone la ruta\n",
        "dataset = NYUDatasetNoDepth(\n",
        "    rgb_dir=rgb_dir,\n",
        "    input_size=256,\n",
        "    dof_levels=5,\n",
        ")\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "jCiRu974pYVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(batch, max_images=8):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import torchvision.transforms.functional as F\n",
        "\n",
        "    images = batch['image']\n",
        "    gts    = batch['gt']\n",
        "    dofs   = batch['dof']\n",
        "\n",
        "    batch_size = min(images.size(0), max_images)\n",
        "    fig, axs = plt.subplots(batch_size, 2, figsize=(10, 4 * batch_size))\n",
        "\n",
        "    if batch_size == 1:\n",
        "        axs = axs.reshape(1, 2)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = F.to_pil_image(images[i].cpu())\n",
        "        gt  = F.to_pil_image(gts[i].cpu())\n",
        "        dof = dofs[i].item() if hasattr(dofs[i], 'item') else int(dofs[i])\n",
        "\n",
        "        axs[i, 0].imshow(img)\n",
        "        axs[i, 0].set_title(f'Input (DoF {dof})')\n",
        "        axs[i, 0].axis('off')\n",
        "\n",
        "        axs[i, 1].imshow(gt)\n",
        "        axs[i, 1].set_title('Ground Truth')\n",
        "        axs[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "batch = next(iter(dataloader))\n",
        "show_batch(batch)"
      ],
      "metadata": {
        "id": "BovkjbkDpZiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split del dataset\n",
        "train_ratio = 0.7\n",
        "total_size = len(dataset)\n",
        "train_size = int(total_size * train_ratio)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
        "\n",
        "# Modelo, pérdida y optimizador\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Uformer(img_size=256, embed_dim=32, win_size=8, token_projection='linear', token_mlp='leff', depths=[1, 2, 8, 8, 2, 8, 8, 2, 1], modulator=True, dd_in=3).to(device)\n",
        "criterion = CharbonnierLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "6fV_PaanpbNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "    inputs = batch['image'].to(device)\n",
        "    targets = batch['gt'].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "  epoch_loss = running_loss / len(train_loader.dataset)\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "  torch.save(model.state_dict(), f'uformer_epoch{epoch+1}.pth')"
      ],
      "metadata": {
        "id": "Sps0Y2KpphzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluación en test\n",
        "model.eval()\n",
        "psnr_list, ssim_list = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(test_loader, desc=\"Evaluando en test\"):\n",
        "    inputs = batch['image'].to(device)\n",
        "    targets = batch['gt'].to(device)\n",
        "    outputs = model(inputs)\n",
        "    outputs = torch.clamp(outputs, 0, 1)\n",
        "\n",
        "    outputs_np = outputs.cpu().numpy()\n",
        "    targets_np = targets.cpu().numpy()\n",
        "    for i in range(outputs_np.shape[0]):\n",
        "      out_img = outputs_np[i].transpose(1,2,0)\n",
        "      gt_img = targets_np[i].transpose(1,2,0)\n",
        "      psnr = psnr_loss(out_img, gt_img, data_range=1)\n",
        "      ssim = ssim_loss(out_img, gt_img, data_range=1, channel_axis=2)\n",
        "      psnr_list.append(psnr)\n",
        "      ssim_list.append(ssim)\n",
        "\n",
        "print(f\"PSNR promedio en test: {np.mean(psnr_list):.4f}\")\n",
        "print(f\"SSIM promedio en test: {np.mean(ssim_list):.4f}\")"
      ],
      "metadata": {
        "id": "FI5cCnIhpjYg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}